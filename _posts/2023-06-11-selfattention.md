---
layout:       post
title:        "Self Attention"
author:       "Ke"
header-style: text
catalog:      true
mathjax: true
tags:
    - Transformer
---

# Attention is All You Need 


Self-attention 就本质上是依然是一种特殊的 Attention。是种应用在 Transformer 中最重要的结构之一。  

 Attention机制能够帮我们找到子序列和全局的相关度的关系，也就是找到权重值$w_i$.Self-attention 对于 Attention 的变化，其实就是寻找权重值 $w_i$的过程不同。原来，我们计算时使用的是子序列和全局，而现在我们计算 Self-attention 时，用的是自己和自己，这是 Attention 和 Self-attention 从计算上来说最大的区别。

 ## Self-attention的运算过程
 为了能够产生输出的向量 $y_i$，Self-attention 其实是对所有的输入做了一个加权平均的操作，这个公式和 Attention 是一致的  
 $$ y_i=\sum_j w_{ij} x_j$$
 $j$代表整个序列的长度，并且 $j$个权重的相加之和等于 1。值得一提的是，这里的$w_{ij}$
 并不是一个需要神经网络学习的参数，它是来源于$x_i$ 和 $x_j$（这里 $x_i$ 和 $x_j$就都是自己 self）的之间的计算的结果。而它们之间最简单的一种计算方式，就是使用点积的方式。
 $$ w_{ij}^{'}=x_i^{T}x_j.$$
 这个点积的输出的取值范围在负无穷和正无穷之间，所以我们要使用一个 Softmax 把它映射到$[0,1]$之间，并且要确保它们对于整个序列而言的和为 1.  
 $$w_{ij}=\frac{exp w_{ij}^{'}}{\sum_j exp w_{ij}^{'}}$$

 ## Attention 和 Self-attention 的区别是什么?

- 在神经网络中，通常来说你会有输入层（Input），应用激活函数后的输出层（Output），在 RNN 当中你会有状态（State）。如果 Attention (AT) 被应用在某一层的话，它更多的是被应用在输出或者是状态层上，而当我们使用 Self-attention（SA），这种注意力的机制更多的是在关注 Input 自己身上。
- SA 可以在一个模型当中被多次的、独立的使用（比如说在Transformer中，使用了18次；在Bert当中使用12次）。但是，AT在一个模型当中经常只是被使用一次，并且起到连接两个组件的作用。两个不同的组件（Component），编码器和解码器。但是如果我们用 SA，它就不是关注的两个组件，它只是在关注你应用的那一个组件。那这里他就不会去关注解码器了，就比如说在 Bert 中，使用的情况，我们就没有解码器。
- SA 可以在一个模型当中被多次的、独立的使用（比如说在 Transformer 中，使用了18次；在Bert当中使用 12次）。但是，AT 在一个模型当中经常只是被使用一次，并且起到连接两个组件的作用。
- SA 比较擅长在一个序列当中，寻找不同部分之间的关系。比如说，在词法分析的过程中，能够帮助去理解不同词之间的关系。AT 却更擅长寻找两个序列之间的关系，比如说在翻译任务当中，原始的文本和翻译后的文本。这里也要注意，在翻译任务重，SA 也很擅长，比如说 Transformer。
- AT 可以连接两种不同的模态，比如说图片和文字。SA 更多的是被应用在同一种模态上，但是如果一定要使用SA来做的话，也可以将不同的模态组合成一个序列，再使用 SA。 

大部分情况，SA 这种结构更加的 general，在很多任务作为降维、特征表示、特征交叉等功能尝试着应用，很多时候效果都不错。

## Self-attention 为什么能 work?
考虑一个电影推荐系统，你要推荐给用户们一些他们更喜欢的电影，以便用户能够获得更好的体验。
一个可行的方法就是手动获取你电影中的特征，比如说这部电影关于爱情的部分有多少，关于动作的部分有多少；然后我们再去对用户的特征进行分析，比如说用户 A 对于爱情电影的喜爱程度有多少，对动作电影的喜爱程度有多少。如果我们按照上述方式构建了用户和电影的两个矩阵，那么它们的点积就会给你一个分数，这个分数就代表了用户对于某种电影的喜爱程度。
![img](/img/in-post/post-self-attention/score.jpg)
通过上面的这种计算方式，我们就能够得到一些 Score 值。这些值有正数也有负数。比如说，电影是一部关于爱情的电影，并且用户也很喜欢爱情电影，那么这个分值就是一个正数；如果电影是关于爱情的，但是用户却不喜欢爱情电影，那么这个分值就会是一个负值。

还有，这个分值的大小也表示了在某个属性上，它的程度是多大：比如说某一部电影，可能它的内容中只有一点点是关于爱情的，那么它的这个值就会很小；或者说有个用户他不是很喜欢爱情电影，那么这个值的绝对值就会很大，说明他对这种电影的偏见是很大的。

显而易见，上面说的这种方法在现实中是很难实现的。我们很难去人工标注上千万的电影的特征，和用户喜欢哪种类型的电影的分值。

![img](/img/in-post/post-self-attention/basic-self-attn.jpg)

上图是自注意力机制实现的一个方法概览。


